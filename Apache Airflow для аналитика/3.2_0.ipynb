{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59953720",
   "metadata": {},
   "source": [
    "# Apache Airflow для аналитика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65880c6a",
   "metadata": {},
   "source": [
    "# Решение примера на Airflow: практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac44a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "CON = sqlite3.connect('example.db')\n",
    "\n",
    "# Повторим предыдущий код с небольшим измененеием, теперь файлы \n",
    "# записываются на диск, а не передаются в потоке исполнения\n",
    "# это особенность работы Airflow которую мы обсудим позднее\n",
    "# **context это необязательный аргумент, но мы будем его использовать далее\n",
    "# это мощный инструмент который позволит нам писать идемпотентные скрипты\n",
    "\n",
    "def extract_data(url, tmp_file, **context):\n",
    "    pd.read_csv(url).to_csv(tmp_file) # Изменение to_csv, запишем данные в файл\n",
    "\n",
    "\n",
    "def transform_data(group, agreg, tmp_file, tmp_agg_file, **context):\n",
    "    data = pd.read_csv(tmp_file) # Изменение read_csv\n",
    "    data.groupby(group).agg(agreg).reset_index().to_csv(tmp_agg_file) # Изменение to_csv, запишем данные в файл\n",
    " \n",
    "\n",
    "def load_data(tmp_file, table_name, conn=CON, **context):\n",
    "    data = pd.read_csv(tmp_file)# Изменение read_csv, прочитаем данные из файла\n",
    "    data[\"insert_time\"] = pd.to_datetime(\"now\")\n",
    "    data.to_sql(table_name, conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f53deb3",
   "metadata": {},
   "source": [
    "Этот код выполняет то же действие, что и предыдущий, за исключением небольших изменений. Вы, возможно, обратили внимание, что появилась новая структура DAG. Мы уже обсуждали её ранее, но не в контексте Airflow. Кроме того, некоторые функции исчезли, а другие были видоизменены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4c058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \\\n",
    "# apache-airflow==1.10.10 \\\n",
    "# --constraint \\\n",
    "#        https://raw.githubusercontent.com/apache/airflow/1.10.10/requirements/requirements-python3.7.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f5b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимые импорты\n",
    "\n",
    "#from airflow import DAG\n",
    "#from airflow.utils.dates import days_ago\n",
    "#from airflow.operators.email_operator import EmailOperator\n",
    "#from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "# Создаем DAG(контейнер) в который поместим наши задачи\n",
    "# Для DAG-а характерны нужно задать следующие обязательные атрибуты\n",
    "# - Уникальное имя\n",
    "# - Интервал запусков\n",
    "# - Начальная точка запуска\n",
    "\n",
    "#dag = DAG(dag_id='dag', # Имя нашего дага, уникальное\n",
    "#         default_args={'owner': 'airflow'}, # Список необязательных аргументов\n",
    "#         schedule_interval='@daily', # Интервал запусков, в данном случае 1 раз в день 24:00\n",
    "#         start_date=days_ago(1) # Начальная точка запуска, это с какого моменты мы бы хотели чтобы скрипт начал исполняться (далее разберем это подробнее)\n",
    "#    )\n",
    "\n",
    " \n",
    "# Создадим задачу которая будет запускать питон функция\n",
    "# Все именно так, создаем код для запуска другого кода\n",
    "#extract_data = PythonOperator(\n",
    "#    task_id='extract_data', # Имя задачи внутри Dag\n",
    "#    python_callable=extract_data, # Запускаемая Python функция, описана выше\n",
    "        \n",
    "    # Чтобы передать аргументы в нашу функцию \n",
    "    # их следует передавать через следующий код\n",
    "#    op_kwargs={\n",
    "#        'url': 'https://raw.githubusercontent.com/dm-novikov/stepik_airflow_course/main/data/data.csv',\n",
    "#        'tmp_file': '/tmp/file.csv'}\n",
    "#    )\n",
    "\n",
    "#transform_data = PythonOperator(\n",
    "#    task_id='transform_data',\n",
    "#    python_callable=transform_data,\n",
    "#    op_kwargs={\n",
    "#        'tmp_file': '/tmp/file.csv',\n",
    "#        'tmp_agg_file': '/tmp/file_agg.csv',\n",
    "#        'group': ['A', 'B', 'C'],\n",
    "#        'agreg': {\"D\": sum}}\n",
    "#    )\n",
    "\n",
    "#load_data = PythonOperator(\n",
    "#    task_id='load_data',\n",
    "#    python_callable=load_data,\n",
    "#    op_kwargs={\n",
    "#        'tmp_file': '/tmp/file_agg.csv',\n",
    "#        'table_name': 'table'}\n",
    "#    )\n",
    "\n",
    "# Создадим задачу которая будет отправлять файл на почту\n",
    "# НЕОБЯЗАТЕЛЬНЫЙ ШАГ (не поддерживает в курсе, вы можете самостоятельно с этим разобраться)\n",
    "# email_op = EmailOperator(\n",
    "#    task_id='send_email',\n",
    "#    to=\"stepikairflowcourse@yandex.ru\",\n",
    "#    subject=\"Test Email Please Ignore\",\n",
    "#    html_content=None,\n",
    "#    files=['/tmp/file_agg.csv']\n",
    "#)\n",
    "\n",
    "# Создадим порядок выполнения задач\n",
    "# В данном случае 2 задачи буудт последователньы и ещё 2 парараллельны\n",
    "#extract_data >> transform_data >> load_data #[load_data, email_op] если решили запустить с Email оператором"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3806e43",
   "metadata": {},
   "source": [
    "\n",
    "_____________________________________________________________________________________________________________________________\n",
    "Проектную работу выполнила: аналитик данных Малахова Наталья\n",
    "\n",
    "Мой телеграм-канал: [Дневник аналитика](https://t.me/diary_musician_analyst \"Дневник аналитика\")\n",
    "\n",
    "GitHub: [GitHub](https://github.com/Malakhova-Natalya \"GitHub\")\n",
    "\n",
    "Habr: [Habr](https://habr.com/ru/users/Malakhova-Natalya/publications/articles/ \"Habr\")\n",
    "\n",
    "Спасибо за внимание!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
