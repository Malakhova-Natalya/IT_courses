# необходимые импорты
from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.operators.python_operator import PythonOperator
import sqlite3

# БД, с которой будем работать
CON = sqlite3.connect('sqlite3.db')

# функции, которые будем использовать
def extract_data(url, tmp_file, **context):
    pd.read_csv(url).to_csv(tmp_file) # изменение to_csv, запишем данные в файл
    
def transform_data(group, agreg, tmp_file, tmp_agg_file, **context):
    data = pd.read_csv(tmp_file) # изменение read_csv
    data.groupby(group).agg(agreg).reset_index().to_csv(tmp_agg_file) # изменение to_csv, запишем данные в файл
    
def merge_data(data1, data2, tmp_file):
    result=data1.merge(data2, on='date')
    pd.read_csv(result).to_csv(tmp_file)
 
def load_data(tmp_file, table_name, conn=CON, **context):
    data = pd.read_csv(tmp_file) # изменение read_csv, прочитаем данные из файла
    data["insert_time"] = pd.to_datetime("now")
    data.to_sql(table_name, conn, if_exists='replace', index=False)
    
    
# создаём DAG, в который поместим наши задачи
dag = DAG(dag_id='685612281', # уникальное имя дага
         default_args={'owner': 'airflow'}, # список необязательных аргументов
         schedule_interval='@daily', # интервал запусков, в данном случае 1 раз в день 24:00
         start_date=datetime.fromisoformat('2021-01-01'),
         end_date=datetime.fromisoformat('2021-01-04')
    )

# задача для скачивания курса валюты 
extract_excangerate = PythonOperator(
    task_id='extract_excangerate', # имя задачи внутри Dag
    dag=dag,
    python_callable=extract_data, # запускаемая Python функция, описана выше
    # аргументы функции
    op_kwargs={
        'url': 'https://raw.githubusercontent.com/datanlnja/airflow_course/main/excangerate/{{ ds }}.csv',
        'tmp_file': '/usr/local/airflow/dags/sandbox/685612281/file1.csv'}
    )

# задача для скачивания логов финансовых транзакций 
extract_data = PythonOperator(
    task_id='extract_data',
    dag=dag,
    python_callable=extract_data, 
    op_kwargs={
        'url': 'https://raw.githubusercontent.com/datanlnja/airflow_course/main/data/{{ ds }}.csv',
        'tmp_file': '/usr/local/airflow/dags/sandbox/685612281/file2.csv'}
    )

# задача объединения данных по дате
merge_data = PythonOperator(
    task_id='merge_data',
    dag=dag,
    python_callable = merge_data,
    op_kwargs={
        'data1':'/usr/local/airflow/dags/sandbox/685612281/file1.csv',
        'data2':'/usr/local/airflow/dags/sandbox/685612281/file2.csv',
        'tmp_file': '/usr/local/airflow/dags/sandbox/685612281/file_merged.csv'}
    )

# задача загрузки данных в БД
load_data = PythonOperator(
    task_id='load_data',
    dag=dag,
    python_callable=load_data,
    op_kwargs={
        'tmp_file': '/usr/local/airflow/dags/sandbox/685612281/file_merged.csv',
        'table_name': 'table'}
    )

# порядок выполнения задач
extract_excangerate >> extract_data >> merge_data >> load_data